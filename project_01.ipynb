{"cells":[{"cell_type":"markdown","metadata":{"id":"jhz3lq_J3Za3"},"source":["## Load packages"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":1992,"status":"ok","timestamp":1706997280070,"user":{"displayName":"Wei Hou","userId":"02037631333897036641"},"user_tz":480},"id":"YI6Ngu5C3Za5"},"outputs":[],"source":["import pandas as pd\n","from sklearn import preprocessing\n","import numpy as np\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn import metrics\n","from sklearn.ensemble import RandomForestClassifier\n","\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms"]},{"cell_type":"markdown","metadata":{"id":"y5d-oHKL3Za6"},"source":["## Function to load data"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":583,"status":"ok","timestamp":1706997284193,"user":{"displayName":"Wei Hou","userId":"02037631333897036641"},"user_tz":480},"id":"TSaYm---3Za6"},"outputs":[],"source":["def parse_telecom_data(filename_train,filename_test):\n","    '''\n","    Takes filename and returns X and Y after applying label encoding and OneHotEncoding\n","\n","    Input:\n","        filename: name of CSV file to read\n","    Output:\n","        X: nparray of X data\n","        Y: nparray of labels\n","    '''\n","    X_train_in = pd.read_csv(filename_train)\n","    X_test_in = pd.read_csv(filename_test)\n","    ID_test = X_test_in[['customerID']].to_numpy()\n","\n","    # get X with categorical data\n","    X_train_cat = X_train_in.drop(columns=['customerID','tenure','MonthlyCharges','TotalCharges','Discontinued'])\n","    X_test_cat = X_test_in.drop(columns=['customerID','tenure','MonthlyCharges','TotalCharges'])\n","\n","    # get X with numeric data\n","    X_train_num = X_train_in[['tenure','MonthlyCharges']].to_numpy()\n","    X_test_num = X_test_in[['tenure','MonthlyCharges']].to_numpy()\n","\n","    # get Y\n","    Y_train_cat = X_train_in.filter(['Discontinued'])\n","\n","    # convert labels to numeric using LabelEncoder\n","    le = preprocessing.LabelEncoder()\n","    colList = X_train_cat.columns\n","    ncol_le = len(colList)\n","    m_train_rows = X_train_cat.shape[0]\n","    m_test_rows = X_test_cat.shape[0]\n","    X_train_le = np.zeros((m_train_rows,ncol_le))\n","    X_test_le = np.zeros((m_test_rows,ncol_le))\n","    for jdx in range(0,ncol_le):\n","        le.fit(X_train_cat[colList[jdx]])\n","        X_train_le[:,jdx] = le.transform(X_train_cat[colList[jdx]])\n","        X_test_le[:,jdx] = le.transform(X_test_cat[colList[jdx]])\n","    \n","    # get labels for training data\n","    Y_train = Y_train_cat.apply(le.fit_transform)\n","    Y_train = Y_train.to_numpy()\n","\n","    # use OneHotEncoder (applied to encoded labels)\n","    enc = preprocessing.OneHotEncoder()\n","    enc.fit(X_train_le)\n","    X_train_ohl = enc.transform(X_train_le).toarray()\n","    X_test_ohl = enc.transform(X_test_le).toarray()\n","\n","    # combine data\n","    n_ohl = X_train_ohl.shape[1]\n","    n_num = X_train_num.shape[1]\n","    X_train = np.zeros((m_train_rows,n_ohl+n_num))\n","    X_test = np.zeros((m_test_rows,n_ohl+n_num))\n","    X_train[:,0:n_ohl] = X_train_ohl\n","    X_test[:,0:n_ohl] = X_test_ohl\n","    X_train[:,n_ohl:] = X_train_num\n","    X_test[:,n_ohl:] = X_test_num\n","\n","    return X_train,Y_train,X_test,ID_test"]},{"cell_type":"markdown","metadata":{"id":"fYyYW1183Za6"},"source":["## Load Data"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"elapsed":1242,"status":"error","timestamp":1706997295232,"user":{"displayName":"Wei Hou","userId":"02037631333897036641"},"user_tz":480},"id":"tiV4Vq5A3Za7"},"outputs":[],"source":["# get data\n","[X_train,Y_train,X_test,ID_test] = parse_telecom_data(filename_train='train.csv',filename_test='test.csv');\n","\n","# check for NaN\n","if np.isnan(X_train).any():\n","    print('NaN in training data');\n","if np.isnan(X_test).any():\n","    print('NaN in test data');"]},{"cell_type":"markdown","metadata":{},"source":["## EDA"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["X_train_in = pd.read_csv('train.csv')\n","X_test_in = pd.read_csv('test.csv')"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"data":{"text/plain":["array([[1],\n","       [0],\n","       [1],\n","       ...,\n","       [1],\n","       [0],\n","       [1]])"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["Y_train"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>customerID</th>\n","      <th>gender</th>\n","      <th>SeniorCitizen</th>\n","      <th>Partner</th>\n","      <th>Dependents</th>\n","      <th>tenure</th>\n","      <th>PhoneService</th>\n","      <th>MultipleLines</th>\n","      <th>InternetService</th>\n","      <th>OnlineSecurity</th>\n","      <th>...</th>\n","      <th>DeviceProtection</th>\n","      <th>TechSupport</th>\n","      <th>StreamingTV</th>\n","      <th>StreamingMovies</th>\n","      <th>Contract</th>\n","      <th>PaperlessBilling</th>\n","      <th>PaymentMethod</th>\n","      <th>MonthlyCharges</th>\n","      <th>TotalCharges</th>\n","      <th>Discontinued</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1915-IOFGU</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>1</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Fiber optic</td>\n","      <td>No</td>\n","      <td>...</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>Month-to-month</td>\n","      <td>No</td>\n","      <td>Electronic check</td>\n","      <td>70.50</td>\n","      <td>70.50</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>6728-CZFEI</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>15</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>DSL</td>\n","      <td>No</td>\n","      <td>...</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>One year</td>\n","      <td>No</td>\n","      <td>Mailed check</td>\n","      <td>56.15</td>\n","      <td>931.90</td>\n","      <td>No</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3863-IUBJR</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>12</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>DSL</td>\n","      <td>No</td>\n","      <td>...</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>One year</td>\n","      <td>No</td>\n","      <td>Credit card (automatic)</td>\n","      <td>53.65</td>\n","      <td>696.35</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5572-ZDXHY</td>\n","      <td>Female</td>\n","      <td>0</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>22</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Fiber optic</td>\n","      <td>No</td>\n","      <td>...</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Mailed check</td>\n","      <td>84.30</td>\n","      <td>1855.65</td>\n","      <td>Yes</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>8348-HFYIV</td>\n","      <td>Male</td>\n","      <td>0</td>\n","      <td>No</td>\n","      <td>No</td>\n","      <td>2</td>\n","      <td>No</td>\n","      <td>No phone service</td>\n","      <td>DSL</td>\n","      <td>No</td>\n","      <td>...</td>\n","      <td>Yes</td>\n","      <td>No</td>\n","      <td>Yes</td>\n","      <td>Yes</td>\n","      <td>Month-to-month</td>\n","      <td>Yes</td>\n","      <td>Electronic check</td>\n","      <td>49.25</td>\n","      <td>90.35</td>\n","      <td>Yes</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows Ã— 21 columns</p>\n","</div>"],"text/plain":["   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n","0  1915-IOFGU  Female              0      No         No       1          Yes   \n","1  6728-CZFEI  Female              0      No         No      15          Yes   \n","2  3863-IUBJR    Male              0     Yes        Yes      12          Yes   \n","3  5572-ZDXHY  Female              0      No         No      22          Yes   \n","4  8348-HFYIV    Male              0      No         No       2           No   \n","\n","      MultipleLines InternetService OnlineSecurity  ... DeviceProtection  \\\n","0                No     Fiber optic             No  ...               No   \n","1                No             DSL             No  ...               No   \n","2                No             DSL             No  ...               No   \n","3                No     Fiber optic             No  ...               No   \n","4  No phone service             DSL             No  ...              Yes   \n","\n","  TechSupport StreamingTV StreamingMovies        Contract PaperlessBilling  \\\n","0          No          No              No  Month-to-month               No   \n","1          No         Yes              No        One year               No   \n","2          No          No             Yes        One year               No   \n","3          No          No             Yes  Month-to-month              Yes   \n","4          No         Yes             Yes  Month-to-month              Yes   \n","\n","             PaymentMethod MonthlyCharges  TotalCharges  Discontinued  \n","0         Electronic check          70.50         70.50           Yes  \n","1             Mailed check          56.15        931.90            No  \n","2  Credit card (automatic)          53.65        696.35           Yes  \n","3             Mailed check          84.30       1855.65           Yes  \n","4         Electronic check          49.25         90.35           Yes  \n","\n","[5 rows x 21 columns]"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["X_train_in.head()"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["(5343, 45)"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["X_train.shape"]},{"cell_type":"markdown","metadata":{"id":"qt8JCSwZ3Za7"},"source":["## Train Decision Tree Classifier"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"HDhn6yzW3Za7"},"outputs":[],"source":["clf = RandomForestClassifier(n_estimators = 1000,criterion='gini');\n","#clf = DecisionTreeClassifier(criterion='gini');\n","clf.min_samples_leaf = 50;\n","clf.fit(X_train,Y_train.flatten());"]},{"cell_type":"markdown","metadata":{"id":"W88M4Pss3Za7"},"source":["## Compute metric for training data"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":800,"status":"ok","timestamp":1706995654678,"user":{"displayName":"Michael Sleeman","userId":"12982576314584964833"},"user_tz":480},"id":"3V8vGwXn3Za7","outputId":"a2091adf-dab2-4cfc-f9fe-c04a9c51baae"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training metric:  0.8563127960027641\n"]}],"source":["y_train_prob = clf.predict_proba(X_train);\n","thisMetric = metrics.roc_auc_score(Y_train, y_train_prob[:,1]);\n","print(\"Training metric: \",thisMetric)"]},{"cell_type":"markdown","metadata":{"id":"p7Dk4Xkg3Za8"},"source":["## Save test prediction to CSV"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"9qKSl1Eu3Za8"},"outputs":[],"source":["y_test_prob = clf.predict_proba(X_test);\n","thisData = np.concatenate((ID_test, np.reshape(y_test_prob[:,1],(-1,1))), axis=1);\n","thisLabel = ['ID','TARGET'];\n","y_test_prob_pd = pd.DataFrame(data=thisData,columns=thisLabel)\n","fname_submit = 'test_submission.csv';\n","y_test_prob_pd.to_csv(fname_submit,index=False);"]},{"cell_type":"markdown","metadata":{},"source":["## Neural Network"]},{"cell_type":"markdown","metadata":{},"source":["### Init Neural Network Structure"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(5343, 45)\n","(5343, 1)\n"]}],"source":["print(X_train.shape)\n","print(Y_train.shape)"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of training data is  4274\n"]}],"source":["# set batch size\n","batch_size = 32\n","\n","# Prepare dataset using DataLoader\n","class telecomDataset(torch.utils.data.Dataset):\n","    def __init__(self, X, Y):\n","        self.X = X\n","        self.Y = Y\n","    def __len__(self):\n","        return len(self.X)\n","    def __getitem__(self, idx):\n","        return self.X[idx], self.Y[idx]\n","    \n","# create dataset\n","# split training data into training and validation\n","N_train = int(X_train.shape[0] * 4 / 5)\n","print('Number of training data is ',N_train)\n","X_train_train = X_train[0:N_train,:]\n","X_train_val = X_train[N_train:,:]\n","Y_train_train = Y_train[0:N_train]\n","Y_train_val = Y_train[N_train:]\n","\n","# create training dataset\n","train_dataset = telecomDataset(torch.tensor(X_train_train).float(), torch.tensor(Y_train_train).float())\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","\n","# create testing dataset\n","test_dataset = telecomDataset(torch.tensor(X_train_val).float(), torch.tensor(Y_train_val).float())\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["134 training batches\n","4288 training samples\n","34 validation batches\n"]}],"source":["print(f'{len(train_loader)} training batches')\n","print(f'{len(train_loader) * batch_size} training samples')\n","print(f'{len(test_loader)} validation batches')"]},{"cell_type":"code","execution_count":103,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","\n","model = nn.Sequential(\n","    \n","    # nn.Flatten(),\n","    nn.Linear(45, 64),\n","    nn.ReLU(),\n","\n","    nn.Linear(64, 128),\n","    nn.ReLU(),\n","\n","    nn.Dropout(0.5),\n","\n","    nn.Linear(128, 256),\n","    nn.ReLU(),\n","\n","    nn.Linear(256, 256),\n","    nn.ReLU(),\n","\n","    nn.Dropout(0.5),\n","\n","    nn.Linear(256, 64),\n","    nn.ReLU(),\n","\n","    nn.Linear(64, 32),\n","    nn.ReLU(),\n","\n","    nn.Linear(32, 1),\n","\n","    nn.Sigmoid()\n","    # PyTorch implementation of cross-entropy loss includes softmax layer\n",")"]},{"cell_type":"code","execution_count":104,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([64, 45])\n","torch.Size([64])\n","torch.Size([128, 64])\n","torch.Size([128])\n","torch.Size([256, 128])\n","torch.Size([256])\n","torch.Size([256, 256])\n","torch.Size([256])\n","torch.Size([64, 256])\n","torch.Size([64])\n","torch.Size([32, 64])\n","torch.Size([32])\n","torch.Size([1, 32])\n","torch.Size([1])\n"]}],"source":["for p in model.parameters():\n","    print(p.data.shape)"]},{"cell_type":"code","execution_count":105,"metadata":{},"outputs":[],"source":["import torch.optim as optim\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)"]},{"cell_type":"code","execution_count":106,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10:.\n","\tloss: 0.1643, acc: 0.7606, val loss: 0.2072, val acc: 0.7905\n","Epoch 2/10:.\n","\tloss: 0.1510, acc: 0.7803, val loss: 0.2026, val acc: 0.7951\n","Epoch 3/10:.\n","\tloss: 0.1445, acc: 0.7929, val loss: 0.1999, val acc: 0.7979\n","Epoch 4/10:.\n","\tloss: 0.1433, acc: 0.7948, val loss: 0.1944, val acc: 0.8036\n","Epoch 5/10:.\n","\tloss: 0.1402, acc: 0.7990, val loss: 0.2026, val acc: 0.7951\n","Epoch 6/10:.\n","\tloss: 0.1389, acc: 0.7978, val loss: 0.1962, val acc: 0.8017\n","Epoch 7/10:.\n","\tloss: 0.1387, acc: 0.7974, val loss: 0.1916, val acc: 0.8064\n","Epoch 8/10:.\n","\tloss: 0.1387, acc: 0.7976, val loss: 0.1971, val acc: 0.8007\n","Epoch 9/10:.\n","\tloss: 0.1396, acc: 0.7993, val loss: 0.2008, val acc: 0.7970\n","Epoch 10/10:.\n","\tloss: 0.1374, acc: 0.8042, val loss: 0.1907, val acc: 0.8073\n","Epoch 11/10:.\n","\tloss: 0.1382, acc: 0.8002, val loss: 0.1815, val acc: 0.8167\n","Epoch 12/10:.\n","\tloss: 0.1354, acc: 0.8007, val loss: 0.1999, val acc: 0.7979\n","Epoch 13/10:.\n","\tloss: 0.1371, acc: 0.8063, val loss: 0.1953, val acc: 0.8026\n","Epoch 14/10:.\n","\tloss: 0.1379, acc: 0.7985, val loss: 0.1888, val acc: 0.8092\n","Epoch 15/10:.\n","\tloss: 0.1359, acc: 0.8051, val loss: 0.1898, val acc: 0.8082\n","Epoch 16/10:.\n","\tloss: 0.1345, acc: 0.8058, val loss: 0.1971, val acc: 0.8007\n","Epoch 17/10:.\n","\tloss: 0.1345, acc: 0.8063, val loss: 0.1907, val acc: 0.8073\n","Epoch 18/10:.\n","\tloss: 0.1347, acc: 0.8044, val loss: 0.1815, val acc: 0.8167\n","Epoch 19/10:.\n","\tloss: 0.1354, acc: 0.8044, val loss: 0.1925, val acc: 0.8054\n","Epoch 20/10:.\n","\tloss: 0.1364, acc: 0.8009, val loss: 0.2026, val acc: 0.7951\n","Epoch 21/10:.\n","\tloss: 0.1345, acc: 0.8058, val loss: 0.1879, val acc: 0.8101\n","Epoch 22/10:.\n","\tloss: 0.1350, acc: 0.8030, val loss: 0.1898, val acc: 0.8082\n","Epoch 23/10:.\n","\tloss: 0.1347, acc: 0.8028, val loss: 0.1898, val acc: 0.8082\n","Epoch 24/10:.\n","\tloss: 0.1347, acc: 0.8065, val loss: 0.1916, val acc: 0.8064\n","Epoch 25/10:.\n","\tloss: 0.1334, acc: 0.8042, val loss: 0.1925, val acc: 0.8054\n","Epoch 26/10:.\n","\tloss: 0.1318, acc: 0.8091, val loss: 0.1944, val acc: 0.8036\n","Epoch 27/10:.\n","\tloss: 0.1343, acc: 0.8053, val loss: 0.1898, val acc: 0.8082\n","Epoch 28/10:.\n","\tloss: 0.1333, acc: 0.8051, val loss: 0.1870, val acc: 0.8110\n","Epoch 29/10:.\n","\tloss: 0.1323, acc: 0.8070, val loss: 0.1990, val acc: 0.7989\n","Epoch 30/10:.\n","\tloss: 0.1336, acc: 0.8079, val loss: 0.1898, val acc: 0.8082\n","Epoch 31/10:.\n","\tloss: 0.1338, acc: 0.8081, val loss: 0.1898, val acc: 0.8082\n","Epoch 32/10:.\n","\tloss: 0.1334, acc: 0.8091, val loss: 0.1916, val acc: 0.8064\n","Epoch 33/10:.\n","\tloss: 0.1331, acc: 0.8105, val loss: 0.1888, val acc: 0.8092\n","Epoch 34/10:.\n","\tloss: 0.1322, acc: 0.8109, val loss: 0.2017, val acc: 0.7961\n","Epoch 35/10:.\n","\tloss: 0.1326, acc: 0.8112, val loss: 0.1842, val acc: 0.8138\n","Epoch 36/10:.\n","\tloss: 0.1318, acc: 0.8088, val loss: 0.1870, val acc: 0.8110\n","Epoch 37/10:.\n","\tloss: 0.1319, acc: 0.8121, val loss: 0.1925, val acc: 0.8054\n","Epoch 38/10:.\n","\tloss: 0.1315, acc: 0.8102, val loss: 0.1806, val acc: 0.8176\n","Epoch 39/10:.\n","\tloss: 0.1322, acc: 0.8042, val loss: 0.1953, val acc: 0.8026\n","Epoch 40/10:.\n","\tloss: 0.1309, acc: 0.8135, val loss: 0.1953, val acc: 0.8026\n","Epoch 41/10:.\n","\tloss: 0.1318, acc: 0.8074, val loss: 0.1916, val acc: 0.8064\n","Epoch 42/10:.\n","\tloss: 0.1306, acc: 0.8112, val loss: 0.1879, val acc: 0.8101\n","Epoch 43/10:.\n","\tloss: 0.1309, acc: 0.8088, val loss: 0.1888, val acc: 0.8092\n","Epoch 44/10:.\n","\tloss: 0.1304, acc: 0.8140, val loss: 0.1888, val acc: 0.8092\n","Epoch 45/10:.\n","\tloss: 0.1312, acc: 0.8060, val loss: 0.1962, val acc: 0.8017\n","Epoch 46/10:.\n","\tloss: 0.1293, acc: 0.8107, val loss: 0.1898, val acc: 0.8082\n","Epoch 47/10:.\n","\tloss: 0.1298, acc: 0.8095, val loss: 0.1907, val acc: 0.8073\n","Epoch 48/10:.\n","\tloss: 0.1306, acc: 0.8138, val loss: 0.1916, val acc: 0.8064\n","Epoch 49/10:.\n","\tloss: 0.1301, acc: 0.8091, val loss: 0.1953, val acc: 0.8026\n","Epoch 50/10:.\n","\tloss: 0.1295, acc: 0.8131, val loss: 0.1879, val acc: 0.8101\n","Epoch 51/10:.\n","\tloss: 0.1299, acc: 0.8124, val loss: 0.1870, val acc: 0.8110\n","Epoch 52/10:.\n","\tloss: 0.1293, acc: 0.8126, val loss: 0.1944, val acc: 0.8036\n","Epoch 53/10:.\n","\tloss: 0.1293, acc: 0.8142, val loss: 0.2109, val acc: 0.7867\n","Epoch 54/10:.\n","\tloss: 0.1311, acc: 0.8126, val loss: 0.1898, val acc: 0.8082\n","Epoch 55/10:.\n","\tloss: 0.1283, acc: 0.8168, val loss: 0.2017, val acc: 0.7961\n","Epoch 56/10:.\n","\tloss: 0.1298, acc: 0.8095, val loss: 0.1907, val acc: 0.8073\n","Epoch 57/10:.\n","\tloss: 0.1303, acc: 0.8135, val loss: 0.1916, val acc: 0.8064\n","Epoch 58/10:.\n","\tloss: 0.1294, acc: 0.8114, val loss: 0.1953, val acc: 0.8026\n","Epoch 59/10:.\n","\tloss: 0.1282, acc: 0.8173, val loss: 0.1990, val acc: 0.7989\n","Epoch 60/10:.\n","\tloss: 0.1290, acc: 0.8156, val loss: 0.1870, val acc: 0.8110\n","Epoch 61/10:.\n","\tloss: 0.1290, acc: 0.8102, val loss: 0.1861, val acc: 0.8120\n","Epoch 62/10:.\n","\tloss: 0.1274, acc: 0.8163, val loss: 0.1898, val acc: 0.8082\n","Epoch 63/10:.\n","\tloss: 0.1267, acc: 0.8189, val loss: 0.2008, val acc: 0.7970\n","Epoch 64/10:.\n","\tloss: 0.1301, acc: 0.8117, val loss: 0.1953, val acc: 0.8026\n","Epoch 65/10:.\n","\tloss: 0.1279, acc: 0.8149, val loss: 0.2017, val acc: 0.7961\n","Epoch 66/10:.\n","\tloss: 0.1283, acc: 0.8161, val loss: 0.1907, val acc: 0.8073\n","Epoch 67/10:.\n","\tloss: 0.1273, acc: 0.8189, val loss: 0.1944, val acc: 0.8036\n","Epoch 68/10:.\n","\tloss: 0.1270, acc: 0.8182, val loss: 0.1888, val acc: 0.8092\n","Epoch 69/10:.\n","\tloss: 0.1268, acc: 0.8201, val loss: 0.1824, val acc: 0.8157\n","Epoch 70/10:.\n","\tloss: 0.1275, acc: 0.8135, val loss: 0.1980, val acc: 0.7998\n","Epoch 71/10:.\n","\tloss: 0.1275, acc: 0.8175, val loss: 0.1907, val acc: 0.8073\n","Epoch 72/10:.\n","\tloss: 0.1266, acc: 0.8166, val loss: 0.1852, val acc: 0.8129\n","Epoch 73/10:.\n","\tloss: 0.1271, acc: 0.8184, val loss: 0.1953, val acc: 0.8026\n","Epoch 74/10:.\n","\tloss: 0.1264, acc: 0.8219, val loss: 0.1925, val acc: 0.8054\n","Epoch 75/10:.\n","\tloss: 0.1263, acc: 0.8196, val loss: 0.1925, val acc: 0.8054\n","Epoch 76/10:.\n","\tloss: 0.1255, acc: 0.8154, val loss: 0.1944, val acc: 0.8036\n","Epoch 77/10:.\n","\tloss: 0.1272, acc: 0.8152, val loss: 0.1953, val acc: 0.8026\n","Epoch 78/10:.\n","\tloss: 0.1262, acc: 0.8224, val loss: 0.1898, val acc: 0.8082\n","Epoch 79/10:.\n","\tloss: 0.1254, acc: 0.8187, val loss: 0.1980, val acc: 0.7998\n","Epoch 80/10:.\n","\tloss: 0.1248, acc: 0.8196, val loss: 0.1925, val acc: 0.8054\n","Epoch 81/10:.\n","\tloss: 0.1244, acc: 0.8210, val loss: 0.1888, val acc: 0.8092\n","Epoch 82/10:.\n","\tloss: 0.1255, acc: 0.8217, val loss: 0.1934, val acc: 0.8045\n","Epoch 83/10:.\n","\tloss: 0.1256, acc: 0.8201, val loss: 0.1907, val acc: 0.8073\n","Epoch 84/10:.\n","\tloss: 0.1245, acc: 0.8222, val loss: 0.1980, val acc: 0.7998\n","Epoch 85/10:.\n","\tloss: 0.1251, acc: 0.8250, val loss: 0.1916, val acc: 0.8064\n","Epoch 86/10:.\n","\tloss: 0.1240, acc: 0.8198, val loss: 0.2058, val acc: 0.7933\n","Epoch 87/10:.\n","\tloss: 0.1254, acc: 0.8255, val loss: 0.1929, val acc: 0.8064\n","Epoch 88/10:.\n","\tloss: 0.1237, acc: 0.8210, val loss: 0.1966, val acc: 0.8026\n","Epoch 89/10:.\n","\tloss: 0.1247, acc: 0.8236, val loss: 0.2012, val acc: 0.7979\n","Epoch 90/10:.\n","\tloss: 0.1239, acc: 0.8273, val loss: 0.2063, val acc: 0.7914\n","Epoch 91/10:.\n","\tloss: 0.1211, acc: 0.8283, val loss: 0.1957, val acc: 0.8036\n","Epoch 92/10:.\n","\tloss: 0.1239, acc: 0.8262, val loss: 0.1975, val acc: 0.8017\n","Epoch 93/10:.\n","\tloss: 0.1229, acc: 0.8224, val loss: 0.1975, val acc: 0.8017\n","Epoch 94/10:.\n","\tloss: 0.1230, acc: 0.8278, val loss: 0.2045, val acc: 0.7933\n","Epoch 95/10:.\n","\tloss: 0.1244, acc: 0.8217, val loss: 0.2132, val acc: 0.7858\n","Epoch 96/10:.\n","\tloss: 0.1228, acc: 0.8236, val loss: 0.2021, val acc: 0.7970\n","Epoch 97/10:.\n","\tloss: 0.1218, acc: 0.8290, val loss: 0.1994, val acc: 0.7998\n","Epoch 98/10:.\n","\tloss: 0.1209, acc: 0.8336, val loss: 0.2049, val acc: 0.7942\n","Epoch 99/10:.\n","\tloss: 0.1227, acc: 0.8245, val loss: 0.1939, val acc: 0.8054\n","Epoch 100/10:.\n","\tloss: 0.1215, acc: 0.8287, val loss: 0.1975, val acc: 0.8017\n"]}],"source":["n_epochs = 100\n","\n","# store metrics\n","training_accuracy_history = np.zeros([n_epochs, 1])\n","training_loss_history = np.zeros([n_epochs, 1])\n","validation_accuracy_history = np.zeros([n_epochs, 1])\n","validation_loss_history = np.zeros([n_epochs, 1])\n","\n","for epoch in range(n_epochs):\n","    print(f'Epoch {epoch+1}/10:', end='')\n","    train_total = 0\n","    train_correct = 0\n","    # train\n","    model.train()\n","    for i, data in enumerate(train_loader):\n","        images, labels = data\n","        optimizer.zero_grad()\n","        # forward pass\n","        output = model(images)\n","        # calculate categorical cross entropy loss\n","        loss = criterion(output, labels)\n","        # backward pass\n","        loss.backward()\n","        optimizer.step()\n","        \n","        # track training accuracy\n","        output = (output > 0.5).float()\n","        train_total += labels.size(0)\n","        train_correct += (output == labels).sum().item()\n","        # track training loss\n","        training_loss_history[epoch] += loss.item()\n","        # progress update after 180 batches (~1/10 epoch for batch size 32)\n","        if i % 180 == 0: print('.',end='')\n","    training_loss_history[epoch] /= len(train_loader)\n","    training_accuracy_history[epoch] = train_correct / train_total\n","    print(f'\\n\\tloss: {training_loss_history[epoch,0]:0.4f}, acc: {training_accuracy_history[epoch,0]:0.4f}',end='')\n","        \n","    # validate\n","    test_total = 0\n","    test_correct = 0\n","    with torch.no_grad():\n","        model.eval()\n","        for i, data in enumerate(test_loader):\n","            images, labels = data\n","            # forward pass\n","            output = model(images)\n","            # find accuracy\n","            output = (output > 0.5).float()\n","            test_total += labels.size(0)\n","            test_correct += (output == labels).sum().item()\n","            # find loss\n","            loss = criterion(output, labels)\n","            validation_loss_history[epoch] += loss.item()\n","        validation_loss_history[epoch] /= len(test_loader)\n","        validation_accuracy_history[epoch] = test_correct / test_total\n","    print(f', val loss: {validation_loss_history[epoch,0]:0.4f}, val acc: {validation_accuracy_history[epoch,0]:0.4f}')"]},{"cell_type":"code","execution_count":111,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training metric:  0.870708706144556\n"]}],"source":["model.eval()\n","y_train_prob = model(torch.from_numpy(X_train).float()).detach().numpy()\n","thisMetric = metrics.roc_auc_score(Y_train, y_train_prob);\n","print(\"Training metric: \",thisMetric)"]},{"cell_type":"code","execution_count":112,"metadata":{},"outputs":[],"source":["model.eval()\n","y_test_prob = model(torch.from_numpy(X_test).float()).detach().numpy()\n","thisData = np.concatenate((ID_test, np.reshape(y_test_prob[:],(-1,1))), axis=1)\n","thisLabel = ['ID','TARGET']\n","y_test_prob_pd = pd.DataFrame(data=thisData,columns=thisLabel)\n","fname_submit = 'test_submission_Wei.csv'\n","y_test_prob_pd.to_csv(fname_submit,index=False)"]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
