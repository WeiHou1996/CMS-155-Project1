{"cells":[{"cell_type":"markdown","metadata":{"id":"jhz3lq_J3Za3"},"source":["## Load packages"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":1992,"status":"ok","timestamp":1706997280070,"user":{"displayName":"Wei Hou","userId":"02037631333897036641"},"user_tz":480},"id":"YI6Ngu5C3Za5"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\micha\\AppData\\Local\\Temp\\ipykernel_25944\\3130302097.py:1: DeprecationWarning: \n","Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n","(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n","but was not found to be installed on your system.\n","If this would cause problems for you,\n","please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n","        \n","  import pandas as pd\n"]}],"source":["import pandas as pd\n","from sklearn import preprocessing\n","import numpy as np\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn import metrics\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import KFold\n","from sklearn.ensemble import BaggingClassifier"]},{"cell_type":"markdown","metadata":{"id":"y5d-oHKL3Za6"},"source":["## Function to load data"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":583,"status":"ok","timestamp":1706997284193,"user":{"displayName":"Wei Hou","userId":"02037631333897036641"},"user_tz":480},"id":"TSaYm---3Za6"},"outputs":[],"source":["def parse_telecom_data(filename_train,filename_test):\n","    '''\n","    Takes filename and returns X and Y after applying label encoding and OneHotEncoding\n","\n","    Input:\n","        filename: name of CSV file to read\n","    Output:\n","        X: nparray of X data\n","        Y: nparray of labels\n","    '''\n","    X_train_in = pd.read_csv(filename_train)\n","    X_test_in = pd.read_csv(filename_test)\n","    ID_test = X_test_in[['customerID']].to_numpy()\n","\n","    # get X with categorical data\n","    X_train_cat = X_train_in.drop(columns=['customerID','tenure','MonthlyCharges','TotalCharges','Discontinued'])\n","    X_test_cat = X_test_in.drop(columns=['customerID','tenure','MonthlyCharges','TotalCharges'])\n","\n","    # get X with numeric data\n","    X_train_num = X_train_in[['tenure','MonthlyCharges']].to_numpy()\n","    X_test_num = X_test_in[['tenure','MonthlyCharges']].to_numpy()\n","\n","    # get Y\n","    Y_train_cat = X_train_in.filter(['Discontinued'])\n","\n","    # convert labels to numeric using LabelEncoder\n","    le = preprocessing.LabelEncoder()\n","    colList = X_train_cat.columns\n","    ncol_le = len(colList)\n","    m_train_rows = X_train_cat.shape[0]\n","    m_test_rows = X_test_cat.shape[0]\n","    X_train_le = np.zeros((m_train_rows,ncol_le))\n","    X_test_le = np.zeros((m_test_rows,ncol_le))\n","    for jdx in range(0,ncol_le):\n","        le.fit(X_train_cat[colList[jdx]])\n","        X_train_le[:,jdx] = le.transform(X_train_cat[colList[jdx]])\n","        X_test_le[:,jdx] = le.transform(X_test_cat[colList[jdx]])\n","    \n","    # get labels for training data\n","    Y_train = Y_train_cat.apply(le.fit_transform)\n","    Y_train = Y_train.to_numpy()\n","\n","    # use OneHotEncoder (applied to encoded labels)\n","    enc = preprocessing.OneHotEncoder()\n","    enc.fit(X_train_le)\n","    X_train_ohl = enc.transform(X_train_le).toarray()\n","    X_test_ohl = enc.transform(X_test_le).toarray()\n","\n","    # combine data\n","    n_ohl = X_train_ohl.shape[1]\n","    n_num = X_train_num.shape[1]\n","    X_train = np.zeros((m_train_rows,n_ohl+n_num))\n","    X_test = np.zeros((m_test_rows,n_ohl+n_num))\n","    X_train[:,0:n_ohl] = X_train_ohl\n","    X_test[:,0:n_ohl] = X_test_ohl\n","    X_train[:,n_ohl:] = X_train_num\n","    X_test[:,n_ohl:] = X_test_num\n","\n","    return X_train,Y_train,X_test,ID_test"]},{"cell_type":"markdown","metadata":{"id":"fYyYW1183Za6"},"source":["## Load Data"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"elapsed":1242,"status":"error","timestamp":1706997295232,"user":{"displayName":"Wei Hou","userId":"02037631333897036641"},"user_tz":480},"id":"tiV4Vq5A3Za7"},"outputs":[],"source":["# get data\n","[X_train,Y_train,X_test,ID_test] = parse_telecom_data(filename_train='train.csv',filename_test='test.csv');\n","\n","# check for NaN\n","if np.isnan(X_train).any():\n","    print('NaN in training data');\n","if np.isnan(X_test).any():\n","    print('NaN in test data');"]},{"cell_type":"markdown","metadata":{"id":"qt8JCSwZ3Za7"},"source":["## Train Decision Tree Classifier "]},{"cell_type":"code","execution_count":4,"metadata":{"id":"HDhn6yzW3Za7"},"outputs":[],"source":["#clf = RandomForestClassifier(n_estimators = 1000,criterion='gini');\n","clf = DecisionTreeClassifier(criterion='gini');\n","clf.min_samples_leaf = 25;\n","clf.fit(X_train,Y_train.flatten());"]},{"cell_type":"markdown","metadata":{"id":"W88M4Pss3Za7"},"source":["## Compute metric for training data"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":800,"status":"ok","timestamp":1706995654678,"user":{"displayName":"Michael Sleeman","userId":"12982576314584964833"},"user_tz":480},"id":"3V8vGwXn3Za7","outputId":"a2091adf-dab2-4cfc-f9fe-c04a9c51baae"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training metric:  0.8802695275895379\n"]}],"source":["y_train_prob = clf.predict_proba(X_train);\n","thisMetric = metrics.roc_auc_score(Y_train, y_train_prob[:,1]);\n","print(\"Training metric: \",thisMetric)"]},{"cell_type":"markdown","metadata":{},"source":["## Train Bagging Classifier"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training metric:  0.949417039628642\n","Training metric:  0.9873716944473591\n","Training metric:  0.9955812598818341\n","Training metric:  0.9972643827042125\n","Training metric:  0.9983688868306132\n","Training metric:  0.9990512534778628\n","Training metric:  0.999338256310806\n","Training metric:  0.9995658324619833\n"]}],"source":["estimator_range = [2,4,6,8,10,12,14,16];\n","models = [];\n","scores = [];\n","\n","for n_estimators in estimator_range:\n","\n","    # Create bagging classifier\n","    clf = BaggingClassifier(n_estimators = n_estimators)\n","\n","    # Fit the model\n","    clf.fit(X_train,Y_train.flatten())\n","\n","    # compute metric\n","    y_train_prob = clf.predict_proba(X_train);\n","    thisMetric = metrics.roc_auc_score(Y_train, y_train_prob[:,1]);\n","    print(\"Training metric: \",thisMetric)\n","\n","    models.append(clf);\n","    scores.append(thisMetric);"]},{"cell_type":"markdown","metadata":{"id":"p7Dk4Xkg3Za8"},"source":["## Save test prediction to CSV"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"9qKSl1Eu3Za8"},"outputs":[],"source":["y_test_prob = clf.predict_proba(X_test);\n","thisData = np.concatenate((ID_test, np.reshape(y_test_prob[:,1],(-1,1))), axis=1);\n","thisLabel = ['ID','TARGET'];\n","y_test_prob_pd = pd.DataFrame(data=thisData,columns=thisLabel)\n","fname_submit = 'test_submission.csv';\n","y_test_prob_pd.to_csv(fname_submit,index=False);"]}],"metadata":{"colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":0}
